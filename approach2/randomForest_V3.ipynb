{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (1.26.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# import dependences\n",
    "%pip install seaborn\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "def load_dataset(fname=None, new_size=(10, 10)):\n",
    "    if fname is None:\n",
    "        base_dir = os.getcwd()\n",
    "        fname = os.path.join(base_dir, '../elpv-dataset/labels.csv')\n",
    "\n",
    "    data = np.genfromtxt(fname, dtype=['|S19', '<f8', '|S4'], names=[\n",
    "                         'path', 'probability', 'type'])\n",
    "    image_fnames = np.char.decode(data['path'])\n",
    "    probs = data['probability']\n",
    "    types = np.char.decode(data['type'])\n",
    "\n",
    "    def load_cell_image(fname):\n",
    "        with Image.open(fname) as image:\n",
    "            image = image.convert('L')  # Convert to grayscale\n",
    "            image = image.resize(new_size, Image.Resampling.LANCZOS)  # Resize the image\n",
    "            return np.asarray(image)\n",
    "\n",
    "    dir = os.path.dirname(fname)\n",
    "\n",
    "    images = np.array([load_cell_image(os.path.join(dir, fn))\n",
    "                       for fn in image_fnames])\n",
    "\n",
    "    return images, probs, types\n",
    "\n",
    "images, proba, types = load_dataset(new_size=(10, 10))  \n",
    "\n",
    "# # randomly show 16 x 16 images\n",
    "# num_images = 16 * 16\n",
    "# selected_indices = np.random.choice(len(images), num_images, replace=False)\n",
    "# selected_images = images[selected_indices]\n",
    "# selected_proba = proba[selected_indices]\n",
    "# selected_types = types[selected_indices]\n",
    "\n",
    "# fig, axes = plt.subplots(16, 16, figsize=(20, 20))\n",
    "# for i, ax in enumerate(axes.flat):\n",
    "#     ax.imshow(selected_images[i], cmap='gray')\n",
    "#     ax.axis('off')\n",
    "#     label = f'{selected_proba[i]:.2f}, {selected_types[i]}'\n",
    "#     ax.text(0.5, -0.1, label, fontsize=10, ha='center', transform=ax.transAxes)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 51  72  67 ...  71  74  50]\n",
      " [ 65  85  92 ...  74  69  45]\n",
      " [ 56  76  76 ...  85  88  58]\n",
      " ...\n",
      " [149 169 164 ... 146 149 136]\n",
      " [107 135 150 ... 152 160 144]\n",
      " [134 142 139 ... 142 146 130]]\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = images.reshape((images.shape[0], -1))\n",
    "y = (proba > 0.5).astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[170 200 194 ... 154 167 163]\n",
      " [139 140 131 ... 144 151 149]\n",
      " [ 98 148 145 ... 151 153 101]\n",
      " ...\n",
      " [ 94 163 163 ... 173 184 116]\n",
      " [130 162 158 ... 146 149 122]\n",
      " [ 82 106  99 ...  90  87  69]]\n",
      "[0 1 0 ... 0 0 1]\n",
      "[1 1 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "type_encoder = LabelEncoder()\n",
    "types_encoded = type_encoder.fit_transform(types)\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test, types_train, types_test = train_test_split(X, y, types_encoded, test_size=0.25, random_state=42)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(types_train)\n",
    "\n",
    "# Filter out 'mono' and 'poly' samples for separate processing\n",
    "X_train_mono = X_train[types_train == 0]\n",
    "y_train_mono = y_train[types_train == 0]\n",
    "X_test_mono = X_test[types_test == 0]\n",
    "y_test_mono = y_test[types_test == 0]\n",
    "\n",
    "X_train_poly = X_train[types_train == 1]\n",
    "y_train_poly = y_train[types_train == 1]\n",
    "X_test_poly = X_test[types_test == 1]\n",
    "y_test_poly = y_test[types_test == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with PCA and a classifier\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=150)),  # Adjust the number of components\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameters for grid search\n",
    "param_grid = {\n",
    "    'pca__n_components': [50, 100, 150],\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [5, 10, None]\n",
    "}\n",
    "\n",
    "# Create and train a pipeline for 'mono' samples\n",
    "pipe_mono = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=50)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "pipe_mono.fit(X_train_mono, y_train_mono)\n",
    "\n",
    "# Predictions and evaluation for 'mono'\n",
    "y_pred_mono = pipe_mono.predict(X_test_mono)\n",
    "\n",
    "# Create and train a pipeline for 'poly' samples\n",
    "pipe_poly = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=50)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "pipe_poly.fit(X_train_poly, y_train_poly)\n",
    "\n",
    "# Predictions and evaluation for 'poly'\n",
    "y_pred_poly = pipe_poly.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "45 fits failed out of a total of 135.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 423, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 377, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/memory.py\", line 353, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py\", line 957, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_set_output.py\", line 157, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/decomposition/_pca.py\", line 460, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "               ^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/decomposition/_pca.py\", line 510, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/decomposition/_pca.py\", line 524, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=150 must be between 0 and min(n_samples, n_features)=100 with svd_solver='full'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.78048721 0.76574444        nan 0.76880045 0.76676741        nan\n",
      " 0.77743506 0.76574702        nan 0.79877811 0.79014608        nan\n",
      " 0.80233399 0.80436316        nan 0.80741143 0.80284548        nan\n",
      " 0.80079436 0.79419925        nan 0.81046486 0.80385425        nan\n",
      " 0.80893169 0.80741272        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# accounting accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/stanyan/Github/comp9517-elpv/approach2/randomForest V3.ipynb 单元格 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stanyan/Github/comp9517-elpv/approach2/randomForest%20V3.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtabulate\u001b[39;00m \u001b[39mimport\u001b[39;00m tabulate\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stanyan/Github/comp9517-elpv/approach2/randomForest%20V3.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# 生成混淆矩阵数据\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/stanyan/Github/comp9517-elpv/approach2/randomForest%20V3.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/stanyan/Github/comp9517-elpv/approach2/randomForest%20V3.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m cm_sum \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(cm, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stanyan/Github/comp9517-elpv/approach2/randomForest%20V3.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m cm_perc \u001b[39m=\u001b[39m cm \u001b[39m/\u001b[39m cm_sum\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "\n",
    "# 生成混淆矩阵数据\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "cm_perc = cm / cm_sum.astype(float) * 100\n",
    "annot = np.empty_like(cm).astype(str)\n",
    "\n",
    "# 格式化矩阵数据为百分比和实际值\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        c = cm[i, j]\n",
    "        p = cm_perc[i, j]\n",
    "        annot[i, j] = f'{p:.1f}%\\n({c})'\n",
    "\n",
    "# 自定义类别名称\n",
    "true_class_names = ['0% defective', '100% defective']  # 真实标签的类别名称\n",
    "predicted_class_names = ['0% defective by Pred', '100% defective by Pred']  # 模型预测的类别名称\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', cbar=True, linewidths=0.5, linecolor='gray')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# 设置y轴（True Label）的类别名称\n",
    "plt.yticks(np.arange(len(true_class_names)) + 0.5, true_class_names, rotation=0)\n",
    "\n",
    "# 设置x轴（Predicted Label）的类别名称\n",
    "plt.xticks(np.arange(len(predicted_class_names)) + 0.5, predicted_class_names)\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n",
    "\n",
    "# 打印准确度\n",
    "print(f\"Accuracy on Test Set: {accuracy:.2f}\")\n",
    "\n",
    "# # Plotting confusion matrix\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('True Label')\n",
    "# plt.xlabel('Predicted Label')\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Accuracy on Test Set: {accuracy:.2f}\")\n",
    "\n",
    "# print(\"Classification Report for Mono:\")\n",
    "# print(classification_report(y_test_mono, y_pred_mono))\n",
    "# print(\"Confusion Matrix for Mono:\")\n",
    "# print(confusion_matrix(y_test_mono, y_pred_mono))\n",
    "# print(\"Accuracy for Mono: {:.2f}%\".format(100 * accuracy_score(y_test_mono, y_pred_mono)))\n",
    "\n",
    "\n",
    "# print(\"\\nClassification Report for Poly:\")\n",
    "# print(classification_report(y_test_poly, y_pred_poly))\n",
    "# print(\"Confusion Matrix for Poly:\")\n",
    "# print(confusion_matrix(y_test_poly, y_pred_poly))\n",
    "# print(\"Accuracy for Poly: {:.2f}%\".format(100 * accuracy_score(y_test_poly, y_pred_poly)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
